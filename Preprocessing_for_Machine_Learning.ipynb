{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing for Machine Learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "slgc7PVRWLqf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZki1kKYWANO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "volunteer= pd.read_csv('https://assets.datacamp.com/production/repositories/1816/datasets/668b96955d8b252aa8439c7602d516634e3f015e/volunteer_opportunities.csv')\n",
        "volunteer.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "mmvRn_BoX9y0",
        "outputId": "2e0c75b5-faa7-4d06-cdb5-41d72ba62551"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   opportunity_id  content_id  vol_requests  event_time  \\\n",
              "0            4996       37004            50           0   \n",
              "1            5008       37036             2           0   \n",
              "2            5016       37143            20           0   \n",
              "3            5022       37237           500           0   \n",
              "4            5055       37425            15           0   \n",
              "\n",
              "                                               title  hits  \\\n",
              "0  Volunteers Needed For Rise Up & Stay Put! Home...   737   \n",
              "1                                       Web designer    22   \n",
              "2      Urban Adventures - Ice Skating at Lasker Rink    62   \n",
              "3  Fight global hunger and support women farmers ...    14   \n",
              "4                                      Stop 'N' Swap    31   \n",
              "\n",
              "                                             summary is_priority  category_id  \\\n",
              "0  Building on successful events last summer and ...         NaN          NaN   \n",
              "1             Build a website for an Afghan business         NaN          1.0   \n",
              "2  Please join us and the students from Mott Hall...         NaN          1.0   \n",
              "3  The Oxfam Action Corps is a group of dedicated...         NaN          1.0   \n",
              "4  Stop 'N' Swap reduces NYC's waste by finding n...         NaN          4.0   \n",
              "\n",
              "               category_desc  ...     end_date_date    status Latitude  \\\n",
              "0                        NaN  ...      July 30 2011  approved      NaN   \n",
              "1  Strengthening Communities  ...  February 01 2011  approved      NaN   \n",
              "2  Strengthening Communities  ...   January 29 2011  approved      NaN   \n",
              "3  Strengthening Communities  ...     March 31 2012  approved      NaN   \n",
              "4                Environment  ...  February 05 2011  approved      NaN   \n",
              "\n",
              "   Longitude  Community Board Community Council  Census Tract  BIN  BBL NTA  \n",
              "0        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
              "1        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
              "2        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
              "3        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
              "4        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-685cd405-6191-40fa-ae90-dedbeb81c5ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opportunity_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>vol_requests</th>\n",
              "      <th>event_time</th>\n",
              "      <th>title</th>\n",
              "      <th>hits</th>\n",
              "      <th>summary</th>\n",
              "      <th>is_priority</th>\n",
              "      <th>category_id</th>\n",
              "      <th>category_desc</th>\n",
              "      <th>...</th>\n",
              "      <th>end_date_date</th>\n",
              "      <th>status</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Community Board</th>\n",
              "      <th>Community Council</th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>BIN</th>\n",
              "      <th>BBL</th>\n",
              "      <th>NTA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4996</td>\n",
              "      <td>37004</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>Volunteers Needed For Rise Up &amp; Stay Put! Home...</td>\n",
              "      <td>737</td>\n",
              "      <td>Building on successful events last summer and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>July 30 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5008</td>\n",
              "      <td>37036</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Web designer</td>\n",
              "      <td>22</td>\n",
              "      <td>Build a website for an Afghan business</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>...</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5016</td>\n",
              "      <td>37143</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
              "      <td>62</td>\n",
              "      <td>Please join us and the students from Mott Hall...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>...</td>\n",
              "      <td>January 29 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5022</td>\n",
              "      <td>37237</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>Fight global hunger and support women farmers ...</td>\n",
              "      <td>14</td>\n",
              "      <td>The Oxfam Action Corps is a group of dedicated...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>...</td>\n",
              "      <td>March 31 2012</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5055</td>\n",
              "      <td>37425</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Stop 'N' Swap</td>\n",
              "      <td>31</td>\n",
              "      <td>Stop 'N' Swap reduces NYC's waste by finding n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Environment</td>\n",
              "      <td>...</td>\n",
              "      <td>February 05 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-685cd405-6191-40fa-ae90-dedbeb81c5ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-685cd405-6191-40fa-ae90-dedbeb81c5ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-685cd405-6191-40fa-ae90-dedbeb81c5ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Missing data - rows\n",
        "\n",
        "Taking a look at the volunteer dataset again, we want to drop rows where the category_desc column values are missing. We're going to do this using boolean indexing, by checking to see if we have any null values, and then filtering the dataset so that we only have rows with those values."
      ],
      "metadata": {
        "id": "l_2lKnELYCSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many values are missing in the category_desc column\n",
        "print(volunteer['category_desc'].isnull().sum())\n",
        "\n",
        "# Subset the volunteer dataset\n",
        "volunteer_subset = volunteer[volunteer['category_desc'].notnull()]\n",
        "\n",
        "# Print out the shape of the subset\n",
        "print(volunteer_subset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZcTyVvIYBVY",
        "outputId": "3e5312d6-f332-4a01-e2d4-ed8365f9df02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n",
            "(617, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting a column type\n",
        "\n",
        "If you take a look at the volunteer dataset types, you'll see that the column hits is type object. But, if you actually look at the column, you'll see that it consists of integers. Let's convert that column to type int."
      ],
      "metadata": {
        "id": "HJvby1arpIMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the head of the hits column\n",
        "print(volunteer[\"hits\"].head())\n",
        "\n",
        "# Convert the hits column to type int\n",
        "volunteer[\"hits\"] = volunteer.hits.astype('int')\n",
        "\n",
        "# Look at the dtypes of the dataset\n",
        "print(volunteer.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_9psji-YdnY",
        "outputId": "0996084c-7818-46b6-f369-f40513ecbf13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    737\n",
            "1     22\n",
            "2     62\n",
            "3     14\n",
            "4     31\n",
            "Name: hits, dtype: int64\n",
            "opportunity_id          int64\n",
            "content_id              int64\n",
            "vol_requests            int64\n",
            "event_time              int64\n",
            "title                  object\n",
            "hits                    int64\n",
            "summary                object\n",
            "is_priority            object\n",
            "category_id           float64\n",
            "category_desc          object\n",
            "amsl                  float64\n",
            "amsl_unit             float64\n",
            "org_title              object\n",
            "org_content_id          int64\n",
            "addresses_count         int64\n",
            "locality               object\n",
            "region                 object\n",
            "postalcode            float64\n",
            "primary_loc           float64\n",
            "display_url            object\n",
            "recurrence_type        object\n",
            "hours                   int64\n",
            "created_date           object\n",
            "last_modified_date     object\n",
            "start_date_date        object\n",
            "end_date_date          object\n",
            "status                 object\n",
            "Latitude              float64\n",
            "Longitude             float64\n",
            "Community Board       float64\n",
            "Community Council     float64\n",
            "Census Tract          float64\n",
            "BIN                   float64\n",
            "BBL                   float64\n",
            "NTA                   float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stratified sampling\n",
        "\n",
        "We know that the distribution of variables in the category_desc column in the volunteer dataset is uneven. If we wanted to train a model to try to predict category_desc, we would want to train the model on a sample of data that is representative of the entire dataset. Stratified sampling is a way to achieve this."
      ],
      "metadata": {
        "id": "_7ijrMXkqQZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "6OOvDzz1ren4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data with all columns except category_desc\n",
        "volunteer_X = volunteer.drop(\"category_desc\", axis=1)\n",
        "\n",
        "# Create a category_desc labels dataset\n",
        "volunteer_y = volunteer[[\"category_desc\"]]\n",
        "\n",
        "# Use stratified sampling to split up the dataset according to the volunteer_y dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(volunteer_X, volunteer_y, stratify=volunteer_y)\n",
        "\n",
        "# Print out the category_desc counts on the training y labels\n",
        "print(y_train[\"category_desc\"].value_counts())"
      ],
      "metadata": {
        "id": "sYnJR1f8qSK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling without normalizing\n",
        "\n",
        "Let's take a look at what might happen to your model's accuracy if you try to model data without doing some sort of standardization first. Here we have a subset of the wine dataset. One of the columns, Proline, has an extremely high variance compared to the other columns. This is an example of where a technique like log normalization would come in handy, which you'll learn about in the next section.\n",
        "\n",
        "The scikit-learn model training process should be familiar to you at this point, so we won't go too in-depth with it. You already have a k-nearest neighbors model available (knn) as well as the"
      ],
      "metadata": {
        "id": "Tl4vhxX0tO7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "oqJMgHMgPrOY",
        "outputId": "675a3368-6e99-4aa0-e573-3630ebd656d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Type  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
              "0     1    14.23        1.71  2.43               15.6        127   \n",
              "1     1    13.20        1.78  2.14               11.2        100   \n",
              "2     1    13.16        2.36  2.67               18.6        101   \n",
              "3     1    14.37        1.95  2.50               16.8        113   \n",
              "4     1    13.24        2.59  2.87               21.0        118   \n",
              "\n",
              "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
              "0           2.80        3.06                  0.28             2.29   \n",
              "1           2.65        2.76                  0.26             1.28   \n",
              "2           2.80        3.24                  0.30             2.81   \n",
              "3           3.85        3.49                  0.24             2.18   \n",
              "4           2.80        2.69                  0.39             1.82   \n",
              "\n",
              "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
              "0             5.64  1.04                          3.92     1065  \n",
              "1             4.38  1.05                          3.40     1050  \n",
              "2             5.68  1.03                          3.17     1185  \n",
              "3             7.80  0.86                          3.45     1480  \n",
              "4             4.32  1.04                          2.93      735  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f577bdd-a6f6-4158-876a-105678bf0b34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f577bdd-a6f6-4158-876a-105678bf0b34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f577bdd-a6f6-4158-876a-105678bf0b34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f577bdd-a6f6-4158-876a-105678bf0b34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine= pd.read_csv('https://assets.datacamp.com/production/repositories/1816/datasets/9bd5350dfdb481e0f94eeef6acf2663452a8ef8b/wine_types.csv')\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn= KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
        "           weights='uniform')\n",
        "X= wine[['Proline', 'Total phenols', 'Hue', 'Nonflavanoid phenols']]\n",
        "y= wine[['Type']]"
      ],
      "metadata": {
        "id": "UJATLq0MrvnL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset and labels into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Fit the k-nearest neighbors model to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Score the model on the test data\n",
        "print(knn.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdZ4VzQFO5s0",
        "outputId": "8ed3e80c-eab1-4045-990f-764313ce9026"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log normalization in Python\n",
        "\n",
        "Now that we know that the Proline column in our wine dataset has a large amount of variance, let's log normalize it.\n",
        "\n",
        "Numpy has been imported as np in your workspace."
      ],
      "metadata": {
        "id": "r57AV35tQdqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine.var().sort_values(ascending=False)\n",
        "#proline column has high variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp6a5FniPVFT",
        "outputId": "dae86412-1d8e-49d7-ba2a-985087ef43fc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Proline                         99166.717355\n",
              "Magnesium                         203.989335\n",
              "Alcalinity of ash                  11.152686\n",
              "Color intensity                     5.374449\n",
              "Malic acid                          1.248015\n",
              "Flavanoids                          0.997719\n",
              "Alcohol                             0.659062\n",
              "Type                                0.600679\n",
              "OD280/OD315 of diluted wines        0.504086\n",
              "Total phenols                       0.391690\n",
              "Proanthocyanins                     0.327595\n",
              "Ash                                 0.075265\n",
              "Hue                                 0.052245\n",
              "Nonflavanoid phenols                0.015489\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the variance of the Proline column\n",
        "print(wine.Proline.var())\n",
        "\n",
        "# Apply the log normalization function to the Proline column\n",
        "wine['Proline_log'] = np.log(wine.Proline)\n",
        "\n",
        "# Check the variance of the normalized Proline column\n",
        "print(wine.Proline_log.var())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXntA8rGPbRF",
        "outputId": "811f25c3-9031-4956-db79-614c05b3d80f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99166.71735542436\n",
            "0.17231366191842012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling data - standardizing columns\n",
        "\n",
        "Since we know that the Ash, Alcalinity of ash, and Magnesium columns in the wine dataset are all on different scales, let's standardize them in a way that allows for use in a linear model."
      ],
      "metadata": {
        "id": "5hRzra0QSO7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import StandardScaler from scikit-learn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create the scaler\n",
        "ss = StandardScaler()\n",
        "\n",
        "# Take a subset of the DataFrame you want to scale \n",
        "wine_subset = wine[['Ash', 'Alcalinity of ash', 'Magnesium']]\n",
        "\n",
        "# Apply the scaler to the DataFrame subset\n",
        "wine_subset_scaled = ss.fit_transform(wine_subset)"
      ],
      "metadata": {
        "id": "ioFtfPrKRNfG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN on non-scaled data\n",
        "\n",
        "Let's first take a look at the accuracy of a K-nearest neighbors model on the wine dataset without standardizing the data. The knn model as well as the X and y data and labels sets have been created already. Most of this process of creating models in scikit-learn should look familiar to you."
      ],
      "metadata": {
        "id": "ZcP9uEnzS_BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=wine.drop(['Type', 'Proline_log'], axis=1)\n",
        "y= wine.Type\n",
        "knn= KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
        "           weights='uniform')"
      ],
      "metadata": {
        "id": "NK1GurfeSknG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset and labels into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Fit the k-nearest neighbors model to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Score the model on the test data\n",
        "print(knn.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdxq4bisTGSM",
        "outputId": "2f637939-e167-42cc-f027-3fb427a2cc3d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN on scaled data\n",
        "\n",
        "The accuracy score on the unscaled wine dataset was decent, but we can likely do better if we scale the dataset. The process is mostly the same as the previous exercise, with the added step of scaling the data. Once again, the knn model as well as the X and y data and labels set have already been created for you"
      ],
      "metadata": {
        "id": "9ZmetPm2Tj3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the scaling method.\n",
        "ss = StandardScaler()\n",
        "\n",
        "# Apply the scaling method to the dataset used for modeling.\n",
        "X_scaled = ss.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
        "\n",
        "# Fit the k-nearest neighbors model to the training data.\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Score the model on the test data.\n",
        "print(knn.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtyGixZ3ThCu",
        "outputId": "6b4409dc-9700-41d5-eccc-4a04b40d7a37"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying areas for feature engineering\n",
        "\n",
        "Take an exploratory look at the volunteer dataset, using the variable of that name. Which of the following columns would you want to perform a feature engineering task on?"
      ],
      "metadata": {
        "id": "nmSEx5qVVpwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "volunteer[['title', 'created_date', 'category_desc']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "wx9vEsYfV6ZB",
        "outputId": "142158ea-d94e-439e-82f5-e74e3e61033d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title     created_date  \\\n",
              "0    Volunteers Needed For Rise Up & Stay Put! Home...  January 13 2011   \n",
              "1                                         Web designer  January 14 2011   \n",
              "2        Urban Adventures - Ice Skating at Lasker Rink  January 19 2011   \n",
              "3    Fight global hunger and support women farmers ...  January 21 2011   \n",
              "4                                        Stop 'N' Swap  January 28 2011   \n",
              "..                                                 ...              ...   \n",
              "660          Volunteer for NYLAG's Food Stamps Project   August 16 2011   \n",
              "661    Iridescent Science Studio Open House Volunteers    March 21 2011   \n",
              "662                                  French Translator     July 20 2011   \n",
              "663                  Marketing & Advertising Volunteer     June 01 2011   \n",
              "664  Volunteer filmmakers to help Mayor's Office wi...     July 07 2011   \n",
              "\n",
              "                 category_desc  \n",
              "0                          NaN  \n",
              "1    Strengthening Communities  \n",
              "2    Strengthening Communities  \n",
              "3    Strengthening Communities  \n",
              "4                  Environment  \n",
              "..                         ...  \n",
              "660  Helping Neighbors in Need  \n",
              "661  Strengthening Communities  \n",
              "662  Helping Neighbors in Need  \n",
              "663  Strengthening Communities  \n",
              "664  Strengthening Communities  \n",
              "\n",
              "[665 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5baf042-d278-4253-a3e0-47c8e0d5f408\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>created_date</th>\n",
              "      <th>category_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Volunteers Needed For Rise Up &amp; Stay Put! Home...</td>\n",
              "      <td>January 13 2011</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Web designer</td>\n",
              "      <td>January 14 2011</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
              "      <td>January 19 2011</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fight global hunger and support women farmers ...</td>\n",
              "      <td>January 21 2011</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stop 'N' Swap</td>\n",
              "      <td>January 28 2011</td>\n",
              "      <td>Environment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>Volunteer for NYLAG's Food Stamps Project</td>\n",
              "      <td>August 16 2011</td>\n",
              "      <td>Helping Neighbors in Need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>Iridescent Science Studio Open House Volunteers</td>\n",
              "      <td>March 21 2011</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>French Translator</td>\n",
              "      <td>July 20 2011</td>\n",
              "      <td>Helping Neighbors in Need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>Marketing &amp; Advertising Volunteer</td>\n",
              "      <td>June 01 2011</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>Volunteer filmmakers to help Mayor's Office wi...</td>\n",
              "      <td>July 07 2011</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>665 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5baf042-d278-4253-a3e0-47c8e0d5f408')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5baf042-d278-4253-a3e0-47c8e0d5f408 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5baf042-d278-4253-a3e0-47c8e0d5f408');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding categorical variables - binary\n",
        "\n",
        "Take a look at the hiking dataset. There are several columns here that need encoding, one of which is the Accessible column, which needs to be encoded in order to be modeled. Accessible is a binary feature, so it has two values - either Y or N - so it needs to be encoded into 1s and 0s. Use scikit-learn's LabelEncoder method to do that transformation."
      ],
      "metadata": {
        "id": "_yggOTFBXrrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hiking= pd.read_json('https://assets.datacamp.com/production/repositories/1816/datasets/4f26c48451bdbf73db8a58e226cd3d6b45cf7bb5/hiking.json')\n",
        "hiking.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "KLDpZWEiV_CC",
        "outputId": "3797f1d5-6aa9-4dd1-f7f7-3b2287df4e04"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Prop_ID                     Name  \\\n",
              "0    B057  Salt Marsh Nature Trail   \n",
              "1    B073                Lullwater   \n",
              "\n",
              "                                            Location      Park_Name  \\\n",
              "0  Enter behind the Salt Marsh Nature Center, loc...    Marine Park   \n",
              "1  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
              "\n",
              "      Length Difficulty                                      Other_Details  \\\n",
              "0  0.8 miles       None  <p>The first half of this mile-long trail foll...   \n",
              "1   1.0 mile       Easy  Explore the Lullwater to see how nature thrive...   \n",
              "\n",
              "  Accessible Limited_Access  lat  lon  \n",
              "0          Y              N  NaN  NaN  \n",
              "1          N              N  NaN  NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d5a24a1-2cc5-4603-a628-546decda43ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prop_ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Location</th>\n",
              "      <th>Park_Name</th>\n",
              "      <th>Length</th>\n",
              "      <th>Difficulty</th>\n",
              "      <th>Other_Details</th>\n",
              "      <th>Accessible</th>\n",
              "      <th>Limited_Access</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B057</td>\n",
              "      <td>Salt Marsh Nature Trail</td>\n",
              "      <td>Enter behind the Salt Marsh Nature Center, loc...</td>\n",
              "      <td>Marine Park</td>\n",
              "      <td>0.8 miles</td>\n",
              "      <td>None</td>\n",
              "      <td>&lt;p&gt;The first half of this mile-long trail foll...</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B073</td>\n",
              "      <td>Lullwater</td>\n",
              "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
              "      <td>Prospect Park</td>\n",
              "      <td>1.0 mile</td>\n",
              "      <td>Easy</td>\n",
              "      <td>Explore the Lullwater to see how nature thrive...</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d5a24a1-2cc5-4603-a628-546decda43ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d5a24a1-2cc5-4603-a628-546decda43ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d5a24a1-2cc5-4603-a628-546decda43ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Set up the LabelEncoder object\n",
        "enc = LabelEncoder()\n",
        "\n",
        "# Apply the encoding to the \"Accessible\" column\n",
        "hiking['Accessible_enc'] = enc.fit_transform(hiking.Accessible)\n",
        "\n",
        "# Compare the two columns\n",
        "print(hiking[['Accessible_enc', 'Accessible']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cULTgU2NX2Ao",
        "outputId": "cf6f96e3-523c-4595-ffd1-26e650abb8b4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Accessible_enc Accessible\n",
            "0               1          Y\n",
            "1               0          N\n",
            "2               0          N\n",
            "3               0          N\n",
            "4               0          N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding categorical variables - one-hot\n",
        "\n",
        "One of the columns in the volunteer dataset, category_desc, gives category descriptions for the volunteer opportunities listed. Because it is a categorical variable with more than two categories, we need to use one-hot encoding to transform this column numerically. Use Pandas' get_dummies() function to do so."
      ],
      "metadata": {
        "id": "aS0vQMxfYcYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the category_desc column\n",
        "category_enc = pd.get_dummies(volunteer.category_desc)\n",
        "\n",
        "# Take a look at the encoded columns\n",
        "print(category_enc.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ3TkntSYWYs",
        "outputId": "346967af-d99d-450f-d85e-973b3142e7ab"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Education  Emergency Preparedness  Environment  Health  \\\n",
            "0          0                       0            0       0   \n",
            "1          0                       0            0       0   \n",
            "2          0                       0            0       0   \n",
            "3          0                       0            0       0   \n",
            "4          0                       0            1       0   \n",
            "\n",
            "   Helping Neighbors in Need  Strengthening Communities  \n",
            "0                          0                          0  \n",
            "1                          0                          1  \n",
            "2                          0                          1  \n",
            "3                          0                          1  \n",
            "4                          0                          0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engineering numerical features - taking an average\n",
        "\n",
        "A good use case for taking an aggregate statistic to create a new feature is to take the mean of columns. Here, you have a DataFrame of running times named running_times_5k. For each name in the dataset, take the mean of their 5 run times."
      ],
      "metadata": {
        "id": "Ti9WIE3NcM0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic= {'name': ['Sue' , 'Mark' , 'Sean', 'Erin', 'Jenny', 'Russell'], 'run1': [20.1, 16.5,23.4,21.4,25.4,25.6], 'run2': [18.5, 17.1,26.1,21.1,27.1,29.6]}\n",
        "running_times_5k= pd.DataFrame(dic)"
      ],
      "metadata": {
        "id": "3MpUovvvY9ny"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of the columns to average\n",
        "run_columns = [\"run1\", \"run2\"]\n",
        "\n",
        "# Use apply to create a mean column\n",
        "running_times_5k[\"mean\"] = running_times_5k.apply(lambda row: row[run_columns].mean(), axis=1)\n",
        "\n",
        "# Take a look at the results\n",
        "print(running_times_5k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx6opU2YdT3f",
        "outputId": "cdbe7a60-6e8f-4755-cca1-92f92421a1ea"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      name  run1  run2   mean\n",
            "0      Sue  20.1  18.5  19.30\n",
            "1     Mark  16.5  17.1  16.80\n",
            "2     Sean  23.4  26.1  24.75\n",
            "3     Erin  21.4  21.1  21.25\n",
            "4    Jenny  25.4  27.1  26.25\n",
            "5  Russell  25.6  29.6  27.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engineering numerical features - datetime\n",
        "\n",
        "There are several columns in the volunteer dataset comprised of datetimes. Let's take a look at the start_date_date column and extract just the month to use as a feature for modeling."
      ],
      "metadata": {
        "id": "R8MQqwjdd_3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, convert string column to date column\n",
        "volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer[\"start_date_date\"])\n",
        "\n",
        "# Extract just the month from the converted column\n",
        "volunteer[\"start_date_month\"] = volunteer[\"start_date_converted\"].apply(lambda row: row.month)\n",
        "\n",
        "# Take a look at the converted and new month columns\n",
        "print(volunteer[[\"start_date_converted\", \"start_date_month\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGmZ6s0Md_EF",
        "outputId": "ec99ae35-7afb-4426-8a46-9a671dbc0703"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  start_date_converted  start_date_month\n",
            "0           2011-07-30                 7\n",
            "1           2011-02-01                 2\n",
            "2           2011-01-29                 1\n",
            "3           2011-02-14                 2\n",
            "4           2011-02-05                 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engineering features from strings - extraction\n",
        "\n",
        "The Length column in the hiking dataset is a column of strings, but contained in the column is the mileage for the hike. We're going to extract this mileage using regular expressions, and then use a lambda in Pandas to apply the extraction to the DataFrame."
      ],
      "metadata": {
        "id": "uzGryRQOiGGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using \\d+ to get numbers and \\. to get decimals\n",
        "import re"
      ],
      "metadata": {
        "id": "u0M5nsxJd1qV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a pattern to extract numbers and decimals\n",
        "def return_mileage(length):\n",
        "    pattern = re.compile(r\"\\d+\\.\\d+\")\n",
        "    \n",
        "    # Search the text for matches\n",
        "    mile = re.match(pattern, length)\n",
        "    \n",
        "    # If a value is returned, use group(0) to return the found value\n",
        "    if mile is not None:\n",
        "        return float(mile.group(0))\n",
        "        \n",
        "# Apply the function to the Length column and take a look at both columns\n",
        "hiking[\"Length_num\"] = a.apply(lambda row: return_mileage(row))\n",
        "print(hiking[[\"Length\", \"Length_num\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZOaIuBhgAks",
        "outputId": "67c362e7-8f32-45cb-c4e5-e067c48e2a9b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Length  Length_num\n",
            "0   0.8 miles        0.80\n",
            "1    1.0 mile        1.00\n",
            "2  0.75 miles        0.75\n",
            "3   0.5 miles        0.50\n",
            "4   0.5 miles        0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engineering features from strings - tf/idf\n",
        "\n",
        "Let's transform the volunteer dataset's title column into a text vector, to use in a prediction task in the next exercise."
      ],
      "metadata": {
        "id": "9CD6-H5tlTDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "wBiWPCtgj3ep"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the title text\n",
        "title_text = volunteer.title\n",
        "\n",
        "# Create the vectorizer method\n",
        "tfidf_vec = TfidfVectorizer()\n",
        "\n",
        "# Transform the text into tf-idf vectors\n",
        "text_tfidf = tfidf_vec.fit_transform(title_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfHqvJJ6i8_Q",
        "outputId": "5a52d52f-1286-471d-e716-18a6048e3d5f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<665x1136 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3397 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text classification using tf/idf vectors\n",
        "\n",
        "Now that we've encoded the volunteer dataset's title column into tf/idf vectors, let's use those vectors to try to predict the category_desc column."
      ],
      "metadata": {
        "id": "RkZoIULfoP4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb= GaussianNB(priors=None)\n",
        "# Split the dataset according to the class distribution of category_desc\n",
        "y = volunteer[\"category_desc\"].dropna()\n",
        "X= text_tfidf.toarray()\n",
        "X= X[0:617]\n",
        "X.shape\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
        "\n",
        "# Fit the model to the training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Print out the model's accuracy\n",
        "print(nb.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTNnlmd7jUDB",
        "outputId": "0cf88f2b-c54c-483d-f24e-6cf6effcd854"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2645161290322581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting relevant features\n",
        "\n",
        "Now let's identify the redundant columns in the volunteer dataset and perform feature selection on the dataset to return a DataFrame of the relevant features.\n",
        "\n",
        "For example, if you explore the volunteer dataset in the console, you'll see three features which are related to location: locality, region, and postalcode. They contain repeated information, so it would make sense to keep only one of the features.\n",
        "\n",
        "There are also features that have gone through the feature engineering process: columns like Education and Emergency Preparedness are a product of encoding the categorical variable category_desc, so category_desc itself is redundant now.\n",
        "\n",
        "Take a moment to examine the features of volunteer in the console, and try to identify the redundant features."
      ],
      "metadata": {
        "id": "oHKP5HdOuIwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of redundant column names to drop\n",
        "to_drop = [\"category_desc\", \"created_date\", \"locality\", \"region\", \"vol_requests\"]\n",
        "\n",
        "# Drop those columns from the dataset\n",
        "volunteer_subset = volunteer.drop(to_drop, axis=1)\n",
        "\n",
        "# Print out the head of the new dataset\n",
        "print(volunteer_subset.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od2FZ6d6pRIG",
        "outputId": "48b74c2b-fb9c-45ba-f355-b3bd1185c509"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   opportunity_id  content_id  event_time  \\\n",
            "0            4996       37004           0   \n",
            "1            5008       37036           0   \n",
            "2            5016       37143           0   \n",
            "3            5022       37237           0   \n",
            "4            5055       37425           0   \n",
            "\n",
            "                                               title  hits  \\\n",
            "0  Volunteers Needed For Rise Up & Stay Put! Home...   737   \n",
            "1                                       Web designer    22   \n",
            "2      Urban Adventures - Ice Skating at Lasker Rink    62   \n",
            "3  Fight global hunger and support women farmers ...    14   \n",
            "4                                      Stop 'N' Swap    31   \n",
            "\n",
            "                                             summary is_priority  category_id  \\\n",
            "0  Building on successful events last summer and ...         NaN          NaN   \n",
            "1             Build a website for an Afghan business         NaN          1.0   \n",
            "2  Please join us and the students from Mott Hall...         NaN          1.0   \n",
            "3  The Oxfam Action Corps is a group of dedicated...         NaN          1.0   \n",
            "4  Stop 'N' Swap reduces NYC's waste by finding n...         NaN          4.0   \n",
            "\n",
            "   amsl  amsl_unit  ... Longitude  Community Board  Community Council   \\\n",
            "0   NaN        NaN  ...       NaN              NaN                 NaN   \n",
            "1   NaN        NaN  ...       NaN              NaN                 NaN   \n",
            "2   NaN        NaN  ...       NaN              NaN                 NaN   \n",
            "3   NaN        NaN  ...       NaN              NaN                 NaN   \n",
            "4   NaN        NaN  ...       NaN              NaN                 NaN   \n",
            "\n",
            "   Census Tract  BIN BBL NTA  start_date_converted start_date_month  \\\n",
            "0           NaN  NaN NaN NaN            2011-07-30                7   \n",
            "1           NaN  NaN NaN NaN            2011-02-01                2   \n",
            "2           NaN  NaN NaN NaN            2011-01-29                1   \n",
            "3           NaN  NaN NaN NaN            2011-02-14                2   \n",
            "4           NaN  NaN NaN NaN            2011-02-05                2   \n",
            "\n",
            "                           c  \n",
            "0                        NaN  \n",
            "1  Strengthening Communities  \n",
            "2  Strengthening Communities  \n",
            "3  Strengthening Communities  \n",
            "4                Environment  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking for correlated features\n",
        "\n",
        "Let's take a look at the wine dataset again, which is made up of continuous, numerical features. Run Pearson's correlation coefficient on the dataset to determine which columns are good candidates for eliminating. Then, remove those columns from the DataFrame."
      ],
      "metadata": {
        "id": "FFwW7XavxkZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the column correlations of the wine dataset\n",
        "print(wine.corr())\n",
        "\n",
        "# Take a minute to find the column where the correlation value is greater than 0.75 at least twice\n",
        "to_drop = \"Flavanoids\"\n",
        "\n",
        "# Drop that column from the DataFrame\n",
        "wine = wine.drop(to_drop, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G6FFYAYuzig",
        "outputId": "df235366-c4be-4409-a4cf-86ccd56cbb9d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  Type   Alcohol  Malic acid       Ash  \\\n",
            "Type                          1.000000 -0.328222    0.437776 -0.049643   \n",
            "Alcohol                      -0.328222  1.000000    0.094397  0.211545   \n",
            "Malic acid                    0.437776  0.094397    1.000000  0.164045   \n",
            "Ash                          -0.049643  0.211545    0.164045  1.000000   \n",
            "Alcalinity of ash             0.517859 -0.310235    0.288500  0.443367   \n",
            "Magnesium                    -0.209179  0.270798   -0.054575  0.286587   \n",
            "Total phenols                -0.719163  0.289101   -0.335167  0.128980   \n",
            "Flavanoids                   -0.847498  0.236815   -0.411007  0.115077   \n",
            "Nonflavanoid phenols          0.489109 -0.155929    0.292977  0.186230   \n",
            "Proanthocyanins              -0.499130  0.136698   -0.220746  0.009652   \n",
            "Color intensity               0.265668  0.546364    0.248985  0.258887   \n",
            "Hue                          -0.617369 -0.071747   -0.561296 -0.074667   \n",
            "OD280/OD315 of diluted wines -0.788230  0.072343   -0.368710  0.003911   \n",
            "Proline                      -0.633717  0.643720   -0.192011  0.223626   \n",
            "Proline_log                  -0.569246  0.637325   -0.152643  0.238394   \n",
            "\n",
            "                              Alcalinity of ash  Magnesium  Total phenols  \\\n",
            "Type                                   0.517859  -0.209179      -0.719163   \n",
            "Alcohol                               -0.310235   0.270798       0.289101   \n",
            "Malic acid                             0.288500  -0.054575      -0.335167   \n",
            "Ash                                    0.443367   0.286587       0.128980   \n",
            "Alcalinity of ash                      1.000000  -0.083333      -0.321113   \n",
            "Magnesium                             -0.083333   1.000000       0.214401   \n",
            "Total phenols                         -0.321113   0.214401       1.000000   \n",
            "Flavanoids                            -0.351370   0.195784       0.864564   \n",
            "Nonflavanoid phenols                   0.361922  -0.256294      -0.449935   \n",
            "Proanthocyanins                       -0.197327   0.236441       0.612413   \n",
            "Color intensity                        0.018732   0.199950      -0.055136   \n",
            "Hue                                   -0.273955   0.055398       0.433681   \n",
            "OD280/OD315 of diluted wines          -0.276769   0.066004       0.699949   \n",
            "Proline                               -0.440597   0.393351       0.498115   \n",
            "Proline_log                           -0.416897   0.424006       0.431205   \n",
            "\n",
            "                              Flavanoids  Nonflavanoid phenols  \\\n",
            "Type                           -0.847498              0.489109   \n",
            "Alcohol                         0.236815             -0.155929   \n",
            "Malic acid                     -0.411007              0.292977   \n",
            "Ash                             0.115077              0.186230   \n",
            "Alcalinity of ash              -0.351370              0.361922   \n",
            "Magnesium                       0.195784             -0.256294   \n",
            "Total phenols                   0.864564             -0.449935   \n",
            "Flavanoids                      1.000000             -0.537900   \n",
            "Nonflavanoid phenols           -0.537900              1.000000   \n",
            "Proanthocyanins                 0.652692             -0.365845   \n",
            "Color intensity                -0.172379              0.139057   \n",
            "Hue                             0.543479             -0.262640   \n",
            "OD280/OD315 of diluted wines    0.787194             -0.503270   \n",
            "Proline                         0.494193             -0.311385   \n",
            "Proline_log                     0.410494             -0.275675   \n",
            "\n",
            "                              Proanthocyanins  Color intensity       Hue  \\\n",
            "Type                                -0.499130         0.265668 -0.617369   \n",
            "Alcohol                              0.136698         0.546364 -0.071747   \n",
            "Malic acid                          -0.220746         0.248985 -0.561296   \n",
            "Ash                                  0.009652         0.258887 -0.074667   \n",
            "Alcalinity of ash                   -0.197327         0.018732 -0.273955   \n",
            "Magnesium                            0.236441         0.199950  0.055398   \n",
            "Total phenols                        0.612413        -0.055136  0.433681   \n",
            "Flavanoids                           0.652692        -0.172379  0.543479   \n",
            "Nonflavanoid phenols                -0.365845         0.139057 -0.262640   \n",
            "Proanthocyanins                      1.000000        -0.025250  0.295544   \n",
            "Color intensity                     -0.025250         1.000000 -0.521813   \n",
            "Hue                                  0.295544        -0.521813  1.000000   \n",
            "OD280/OD315 of diluted wines         0.519067        -0.428815  0.565468   \n",
            "Proline                              0.330417         0.316100  0.236183   \n",
            "Proline_log                          0.290203         0.348970  0.173593   \n",
            "\n",
            "                              OD280/OD315 of diluted wines   Proline  \\\n",
            "Type                                             -0.788230 -0.633717   \n",
            "Alcohol                                           0.072343  0.643720   \n",
            "Malic acid                                       -0.368710 -0.192011   \n",
            "Ash                                               0.003911  0.223626   \n",
            "Alcalinity of ash                                -0.276769 -0.440597   \n",
            "Magnesium                                         0.066004  0.393351   \n",
            "Total phenols                                     0.699949  0.498115   \n",
            "Flavanoids                                        0.787194  0.494193   \n",
            "Nonflavanoid phenols                             -0.503270 -0.311385   \n",
            "Proanthocyanins                                   0.519067  0.330417   \n",
            "Color intensity                                  -0.428815  0.316100   \n",
            "Hue                                               0.565468  0.236183   \n",
            "OD280/OD315 of diluted wines                      1.000000  0.312761   \n",
            "Proline                                           0.312761  1.000000   \n",
            "Proline_log                                       0.254218  0.977423   \n",
            "\n",
            "                              Proline_log  \n",
            "Type                            -0.569246  \n",
            "Alcohol                          0.637325  \n",
            "Malic acid                      -0.152643  \n",
            "Ash                              0.238394  \n",
            "Alcalinity of ash               -0.416897  \n",
            "Magnesium                        0.424006  \n",
            "Total phenols                    0.431205  \n",
            "Flavanoids                       0.410494  \n",
            "Nonflavanoid phenols            -0.275675  \n",
            "Proanthocyanins                  0.290203  \n",
            "Color intensity                  0.348970  \n",
            "Hue                              0.173593  \n",
            "OD280/OD315 of diluted wines     0.254218  \n",
            "Proline                          0.977423  \n",
            "Proline_log                      1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring text vectors, part 1\n",
        "\n",
        "Let's expand on the text vector exploration method we just learned about, using the volunteer dataset's title tf/idf vectors. In this first part of text vector exploration, we're going to add to that function we learned about in the slides. We'll return a list of numbers with the function. In the next exercise, we'll write another function to collect the top words across all documents, extract them, and then use that list to filter down our text_tfidf vector."
      ],
      "metadata": {
        "id": "5uqUs8hJytA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add in the rest of the parameters\n",
        "def return_weights(vocab, original_vocab, vector, vector_index, top_n):\n",
        "    zipped = dict(zip(vector[vector_index].indices, vector[vector_index].data))\n",
        "    \n",
        "    # Let's transform that zipped dict into a series\n",
        "    zipped_series = pd.Series({vocab[i]:zipped[i] for i in vector[vector_index].indices})\n",
        "    \n",
        "    # Let's sort the series to pull out the top n weighted words\n",
        "    zipped_index = zipped_series.sort_values(ascending=False)[:top_n].index\n",
        "    return [original_vocab[i] for i in zipped_index]\n",
        "\n",
        "# Print out the weighted words\n",
        "print(return_weights(vocab, tfidf_vec.vocabulary_, text_tfidf, vector_index=8, top_n=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "collapsed": true,
        "id": "JNX5gx-Vxzlz",
        "outputId": "3e067ada-d56b-480f-e415-e4b69d7ca900"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1cec765b8b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Print out the weighted words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring text vectors, part 2\n",
        "\n",
        "Using the function we wrote in the previous exercise, we're going to extract the top words from each document in the text vector, return a list of the word indices, and use that list to filter the text vector down to those top words."
      ],
      "metadata": {
        "id": "XkZcDYHhRfDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def words_to_filter(vocab, original_vocab, vector, top_n):\n",
        "    filter_list = []\n",
        "    for i in range(0, vector.shape[0]):\n",
        "    \n",
        "        # Here we'll call the function from the previous exercise, and extend the list we're creating\n",
        "        filtered = return_weights(vocab, original_vocab, vector, i, top_n)\n",
        "        filter_list.extend(filtered)\n",
        "    # Return the list in a set, so we don't get duplicate word indices\n",
        "    return set(filter_list)\n",
        "\n",
        "# Call the function to get the list of word indices\n",
        "filtered_words = words_to_filter(vocab, tfidf_vec.vocabulary_, text_tfidf, 3)\n",
        "\n",
        "# By converting filtered_words back to a list, we can use it to filter the columns in the text vector\n",
        "filtered_text = text_tfidf[:, list(filtered_words)]"
      ],
      "metadata": {
        "id": "m7Xp5IegROzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Naive Bayes with feature selection\n",
        "\n",
        "Let's re-run the Naive Bayes text classification model we ran at the end of chapter 3, with our selection choices from the previous exercise, on the volunteer dataset's title and category_desc columns."
      ],
      "metadata": {
        "id": "HXUZ-mTDR6bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset according to the class distribution of category_desc, using the filtered_text vector\n",
        "train_X, test_X, train_y, test_y = train_test_split(filtered_text.toarray(), y, stratify=y)\n",
        "\n",
        "# Fit the model to the training data\n",
        "nb.fit(train_X, train_y)\n",
        "\n",
        "# Print out the model's accuracy\n",
        "print(nb.score(test_X, test_y))"
      ],
      "metadata": {
        "id": "pcYsINrmR_Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using PCA\n",
        "\n",
        "Let's apply PCA to the wine dataset, to see if we can get an increase in our model's accuracy."
      ],
      "metadata": {
        "id": "OtY1y9CoTJPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "wine= pd.read_csv('https://assets.datacamp.com/production/repositories/1816/datasets/9bd5350dfdb481e0f94eeef6acf2663452a8ef8b/wine_types.csv')\n"
      ],
      "metadata": {
        "id": "QrNN44gITsUD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Set up PCA and the X vector for diminsionality reduction\n",
        "pca = PCA()\n",
        "wine_X = wine.drop(\"Type\", axis=1)\n",
        "y= wine.Type\n",
        "\n",
        "# Apply PCA to the wine dataset X vector\n",
        "transformed_X = pca.fit_transform(wine_X)\n",
        "\n",
        "# Look at the percentage of variance explained by the different components\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHkAIiFUTK6P",
        "outputId": "9a2b845f-eaf6-4801-a26d-56fe527c2ab1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.98091230e-01 1.73591562e-03 9.49589576e-05 5.02173562e-05\n",
            " 1.23636847e-05 8.46213034e-06 2.80681456e-06 1.52308053e-06\n",
            " 1.12783044e-06 7.21415811e-07 3.78060267e-07 2.12013755e-07\n",
            " 8.25392788e-08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn= KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
        "           weights='uniform')"
      ],
      "metadata": {
        "id": "vdbFth1QTjEg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a model with PCA\n",
        "\n",
        "Now that we have run PCA on the wine dataset, let's try training a model with it."
      ],
      "metadata": {
        "id": "Cv-LWQLTUWMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the transformed X and the y labels into training and test sets\n",
        "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(transformed_X,y)\n",
        "\n",
        "# Fit knn to the training data\n",
        "knn.fit(X_wine_train, y_wine_train)\n",
        "\n",
        "# Score knn on the test data and print it out\n",
        "knn.score(X_wine_test, y_wine_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuQRTJ2jUVBm",
        "outputId": "e9bf2add-4207-4669-8b45-1cce8a00458a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking column types\n",
        "\n",
        "Take a look at the UFO dataset's column types using the dtypes attribute. Two columns jump out for transformation: the seconds column, which is a numeric column but is being read in as object, and the date column, which can be transformed into the datetime type. That will make our feature engineering efforts easier later on."
      ],
      "metadata": {
        "id": "x7nxI63kV8Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ufo= pd.read_csv('https://assets.datacamp.com/production/repositories/1816/datasets/a5ebfe5d2ed194f2668867603b563963af4769e9/ufo_sightings_large.csv')"
      ],
      "metadata": {
        "id": "XzqQMPL2V_5W"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the column types\n",
        "print(ufo.dtypes)\n",
        "\n",
        "# Change the type of seconds to float\n",
        "ufo[\"seconds\"] = ufo.seconds.astype('float')\n",
        "\n",
        "# Change the date column to type datetime\n",
        "ufo[\"date\"] = pd.to_datetime(ufo.date)\n",
        "\n",
        "# Check the column types\n",
        "print(ufo[['seconds', 'date']].dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1E8hUHdWEOI",
        "outputId": "d30f11a2-fea9-43f1-89c6-b6eaf95e4e0d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date               object\n",
            "city               object\n",
            "state              object\n",
            "country            object\n",
            "type               object\n",
            "seconds           float64\n",
            "length_of_time     object\n",
            "desc               object\n",
            "recorded           object\n",
            "lat                object\n",
            "long              float64\n",
            "dtype: object\n",
            "seconds           float64\n",
            "date       datetime64[ns]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropping missing data\n",
        "\n",
        "Let's remove some of the rows where certain columns have missing values. We're going to look at the length_of_time column, the state column, and the type column. If any of the values in these columns are missing, we're going to drop the rows."
      ],
      "metadata": {
        "id": "dKC3WBB6Whg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many values are missing in the length_of_time, state, and type columns\n",
        "print(ufo[[\"length_of_time\", \"state\", \"type\"]].isnull().sum())\n",
        "\n",
        "# Keep only rows where length_of_time, state, and type are not null\n",
        "ufo_no_missing = ufo[ufo[\"length_of_time\"].notnull() & \n",
        "          ufo[\"state\"].notnull() & \n",
        "          ufo[\"type\"].notnull()]\n",
        "\n",
        "# Print out the shape of the new dataset\n",
        "print(ufo_no_missing.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK1MJ3x6WdX4",
        "outputId": "7727ff74-43cc-452e-bccd-79568c919ccb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length_of_time    143\n",
            "state             419\n",
            "type              159\n",
            "dtype: int64\n",
            "(4283, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting numbers from strings\n",
        "\n",
        "The length_of_time field in the UFO dataset is a text field that has the number of minutes within the string. Here, you'll extract that number from that text field using regular expressions."
      ],
      "metadata": {
        "id": "6fUGVnrZuBVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "ufo.length_of_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxxMOzOGuCF_",
        "outputId": "e3fab2e2-ec91-4cee-dbb5-6c9466fd09ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               2 weeks\n",
              "1                30sec.\n",
              "2                   NaN\n",
              "3       about 5 minutes\n",
              "4                     2\n",
              "             ...       \n",
              "4930    about 5 seconds\n",
              "4931         25 seconds\n",
              "4932      early morning\n",
              "4933            2 hours\n",
              "4934          1 minutes\n",
              "Name: length_of_time, Length: 4935, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_minutes(time_string):\n",
        "\n",
        "    # Use \\d+ to grab digits\n",
        "    pattern = re.compile(r\"\\d+\")\n",
        "    \n",
        "    # Use match on the pattern and column\n",
        "    num = re.match(pattern, time_string)\n",
        "    if num is not None:\n",
        "        return int(num.group(0))\n",
        "        \n",
        "# Apply the extraction to the length_of_time column\n",
        "ufo[\"minutes\"] = ufo_no_missing[\"length_of_time\"].apply(lambda x: return_minutes(x))\n",
        "\n",
        "# Take a look at the head of both of the columns\n",
        "print(ufo[['length_of_time', 'minutes']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J314bUmUuKuZ",
        "outputId": "6542c332-4032-428f-a23c-d2ce09d9bfb4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    length_of_time  minutes\n",
            "0          2 weeks      2.0\n",
            "1           30sec.     30.0\n",
            "2              NaN      NaN\n",
            "3  about 5 minutes      NaN\n",
            "4                2      2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying features for standardization\n",
        "\n",
        "In this section, you'll investigate the variance of columns in the UFO dataset to determine which features should be standardized. After taking a look at the variances of the seconds and minutes column, you'll see that the variance of the seconds column is extremely high. Because seconds and minutes are related to each other (an issue we'll deal with when we select features for modeling), let's log normlize the seconds column."
      ],
      "metadata": {
        "id": "f2YZM_XhwEwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the variance of the seconds and minutes columns\n",
        "print(ufo.var())\n",
        "\n",
        "# Log normalize the seconds column\n",
        "ufo[\"seconds_log\"] = np.log(ufo.seconds)\n",
        "\n",
        "# Print out the variance of just the seconds_log column\n",
        "print(ufo.seconds_log.var())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU7cJp2qveIW",
        "outputId": "318ae246-f13a-408a-d9c7-bfbf234f2b95"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seconds        3.156735e+10\n",
            "long           1.824025e+03\n",
            "minutes        9.470577e+02\n",
            "seconds_log             NaN\n",
            "dtype: float64\n",
            "nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.seconds_log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHSSqrwkvijL",
        "outputId": "6ba2a38c-3de4-4491-d06e-a20c59d6f213"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       14.005800\n",
              "1        3.401197\n",
              "2            -inf\n",
              "3        5.703782\n",
              "4            -inf\n",
              "          ...    \n",
              "4930     1.609438\n",
              "4931     3.218876\n",
              "4932         -inf\n",
              "4933     8.881836\n",
              "4934     4.094345\n",
              "Name: seconds_log, Length: 4935, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ufo.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "PWm69EGgxYrc",
        "outputId": "ec363c13-72d6-4f60-f64a-f6404dd3497d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 date              city state country      type    seconds  \\\n",
              "0 2011-11-03 19:21:00         woodville    wi      us   unknown  1209600.0   \n",
              "1 2004-10-03 19:05:00         cleveland    oh      us    circle       30.0   \n",
              "2 2009-09-25 21:00:00       coon rapids    mn      us     cigar        0.0   \n",
              "3 2002-11-21 05:45:00          clemmons    nc      us  triangle      300.0   \n",
              "4 2010-08-19 12:55:00  calgary (canada)    ab      ca      oval        0.0   \n",
              "\n",
              "    length_of_time                                               desc  \\\n",
              "0          2 weeks  Red blinking objects similar to airplanes or s...   \n",
              "1           30sec.               Many fighter jets flying towards UFO   \n",
              "2              NaN  Green&#44 red&#44 and blue pulses of light tha...   \n",
              "3  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
              "4                2     A white spinning disc in the shape of an oval.   \n",
              "\n",
              "     recorded         lat        long  minutes  seconds_log  \n",
              "0  12/12/2011  44.9530556  -92.291111      2.0    14.005800  \n",
              "1  10/27/2004  41.4994444  -81.695556     30.0     3.401197  \n",
              "2  12/12/2009  45.1200000  -93.287500      NaN         -inf  \n",
              "3  12/23/2002  36.0213889  -80.382222      NaN     5.703782  \n",
              "4   8/24/2010   51.083333 -114.083333      2.0         -inf  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00c2b4df-70f8-4749-a3da-07e7d71d0d9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>type</th>\n",
              "      <th>seconds</th>\n",
              "      <th>length_of_time</th>\n",
              "      <th>desc</th>\n",
              "      <th>recorded</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>minutes</th>\n",
              "      <th>seconds_log</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-11-03 19:21:00</td>\n",
              "      <td>woodville</td>\n",
              "      <td>wi</td>\n",
              "      <td>us</td>\n",
              "      <td>unknown</td>\n",
              "      <td>1209600.0</td>\n",
              "      <td>2 weeks</td>\n",
              "      <td>Red blinking objects similar to airplanes or s...</td>\n",
              "      <td>12/12/2011</td>\n",
              "      <td>44.9530556</td>\n",
              "      <td>-92.291111</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004-10-03 19:05:00</td>\n",
              "      <td>cleveland</td>\n",
              "      <td>oh</td>\n",
              "      <td>us</td>\n",
              "      <td>circle</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30sec.</td>\n",
              "      <td>Many fighter jets flying towards UFO</td>\n",
              "      <td>10/27/2004</td>\n",
              "      <td>41.4994444</td>\n",
              "      <td>-81.695556</td>\n",
              "      <td>30.0</td>\n",
              "      <td>3.401197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-09-25 21:00:00</td>\n",
              "      <td>coon rapids</td>\n",
              "      <td>mn</td>\n",
              "      <td>us</td>\n",
              "      <td>cigar</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Green&amp;#44 red&amp;#44 and blue pulses of light tha...</td>\n",
              "      <td>12/12/2009</td>\n",
              "      <td>45.1200000</td>\n",
              "      <td>-93.287500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-11-21 05:45:00</td>\n",
              "      <td>clemmons</td>\n",
              "      <td>nc</td>\n",
              "      <td>us</td>\n",
              "      <td>triangle</td>\n",
              "      <td>300.0</td>\n",
              "      <td>about 5 minutes</td>\n",
              "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
              "      <td>12/23/2002</td>\n",
              "      <td>36.0213889</td>\n",
              "      <td>-80.382222</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.703782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-08-19 12:55:00</td>\n",
              "      <td>calgary (canada)</td>\n",
              "      <td>ab</td>\n",
              "      <td>ca</td>\n",
              "      <td>oval</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>A white spinning disc in the shape of an oval.</td>\n",
              "      <td>8/24/2010</td>\n",
              "      <td>51.083333</td>\n",
              "      <td>-114.083333</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-inf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00c2b4df-70f8-4749-a3da-07e7d71d0d9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00c2b4df-70f8-4749-a3da-07e7d71d0d9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00c2b4df-70f8-4749-a3da-07e7d71d0d9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding categorical variables\n",
        "\n",
        "There are couple of columns in the UFO dataset that need to be encoded before they can be modeled through scikit-learn. You'll do that transformation here, using both binary and one-hot encoding methods."
      ],
      "metadata": {
        "id": "ZjS_fB76yR8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create encode to have US = 1 any other country -\n",
        "ufo['country_enc']= ufo.country.apply(lambda x: 1 if x =='us' else 0)"
      ],
      "metadata": {
        "id": "q15DI_a0xjEP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print out number of unique type vlaues\n",
        "print(ufo.type.nunique())\n",
        "\n",
        "# create dummies for type values\n",
        "type_set= pd.get_dummies(ufo.type)\n",
        "\n",
        "# concat data sets \n",
        "ufo= pd.concat([type_set, ufo])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPqSWhx4y7L1",
        "outputId": "a013cb94-30ce-45a4-f2d9-6bc2f8195295"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features from dates\n",
        "\n",
        "Another feature engineering task to perform is month and year extraction. Perform this task on the date column of the ufo dataset."
      ],
      "metadata": {
        "id": "PLn2-mik0jin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the first 5 rows of the date column\n",
        "print(ufo.date.tail())\n",
        "\n",
        "# Extract the month from the date column\n",
        "ufo[\"month\"] = ufo[\"date\"].apply(lambda x: x.month)\n",
        "\n",
        "# Extract the year from the date column\n",
        "ufo[\"year\"] = ufo[\"date\"].apply(lambda x: x.year)\n",
        "\n",
        "# Take a look at the head of all three columns\n",
        "print(ufo[['date', 'month', 'year']].tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrntScbHzaca",
        "outputId": "0710f52e-de1f-4ecc-93b2-3247f98316c6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4930   2000-07-05 19:30:00\n",
            "4931   2008-03-18 22:00:00\n",
            "4932   2005-06-15 02:30:00\n",
            "4933   1991-11-01 03:00:00\n",
            "4934   2005-12-10 18:00:00\n",
            "Name: date, dtype: datetime64[ns]\n",
            "                    date  month    year\n",
            "4930 2000-07-05 19:30:00    7.0  2000.0\n",
            "4931 2008-03-18 22:00:00    3.0  2008.0\n",
            "4932 2005-06-15 02:30:00    6.0  2005.0\n",
            "4933 1991-11-01 03:00:00   11.0  1991.0\n",
            "4934 2005-12-10 18:00:00   12.0  2005.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text vectorization\n",
        "\n",
        "Let's transform the desc column in the UFO dataset into tf/idf vectors, since there's likely something we can learn from this field."
      ],
      "metadata": {
        "id": "XnmiqedV1oZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# take look at the head of the desc field\n",
        "print(ufo_not.desc.tail())\n",
        "\n",
        "# Create tfidf vectorizer object\n",
        "vec= TfidfVectorizer()\n",
        "\n",
        "# Use vec's fit_transform method on the desc field\n",
        "desc_tfidf= vec.fit_transform(ufo_not.desc)\n",
        "\n",
        "# look at number of columns this creates\n",
        "print(desc_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8WmkL9m1pv9",
        "outputId": "9b2cd539-1ecb-4530-8757-0fc19bb877dc"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4930    On my bike when i saw a shiny silver oval not ...\n",
            "4931    Three sided  stationary object turning clockwi...\n",
            "4932    Cicle object over Washington state all differe...\n",
            "4933    Triangle zigzagged.  Another shined light on u...\n",
            "4934                   Close encounter of the third kind.\n",
            "Name: desc, dtype: object\n",
            "(4932, 6433)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting the ideal dataset\n",
        "\n",
        "Let's get rid of some of the unnecessary features. Because we have an encoded country column, country_enc, keep it and drop other columns related to location: city, country, lat, long, state.\n",
        "\n",
        "We have columns related to month and year, so we don't need the date or recorded columns.\n",
        "\n",
        "We vectorized desc, so we don't need it anymore. For now we'll keep type.\n",
        "\n",
        "We'll keep seconds_log and drop seconds and minutes.\n",
        "\n",
        "Let's also get rid of the length_of_time column, which is unnecessary after extracting minutes."
      ],
      "metadata": {
        "id": "0pGLzqlT4Exe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the correlation between the seconds, seconds_log, and minutes columns\n",
        "print(ufo[['seconds', 'seconds_log', 'minutes']].corr())\n",
        "\n",
        "# Make a list of features to drop\n",
        "to_drop = ufo[['city', 'country', 'lat', 'long', 'state', 'date', 'length_of_time', 'recorded', 'desc', 'seconds', 'minutes']]\n",
        "\n",
        "# Drop those features\n",
        "ufo_dropped = ufo.drop(to_drop, axis=1)\n",
        "\n",
        "# Let's also filter some words out of the text vector we created\n",
        "filtered_words = words_to_filter(vocab, vec.vocabulary_, desc_tfidf, 4)"
      ],
      "metadata": {
        "id": "Gvh-0CmG239H"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling the UFO dataset, part 1\n",
        "\n",
        "In this exercise, we're going to build a k-nearest neighbor model to predict which country the UFO sighting took place in. Our X dataset has the log-normalized seconds column, the one-hot encoded type columns, as well as the month and year when the sighting took place. The y labels are the encoded country column, where 1 is us and 0 is ca"
      ],
      "metadata": {
        "id": "KSmq-qNlJZTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Take a look at the features in the X set of data\n",
        "print(X.columns)\n",
        "\n",
        "# Split the X and y sets using train_test_split, setting stratify=y\n",
        "train_X, test_X, train_y, test_y = train_test_split(X,y, stratify=y)\n",
        "\n",
        "# Fit knn to the training sets\n",
        "knn.fit(train_X, train_y)\n",
        "\n",
        "# Print the score of knn on the test sets\n",
        "print(knn.score(test_X, test_y))"
      ],
      "metadata": {
        "id": "ZwXrLQQGISPy"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling the UFO dataset, part 2\n",
        "\n",
        "Finally, let's build a model using the text vector we created, desc_tfidf, using the filtered_words list to create a filtered text vector. Let's see if we can predict the type of the sighting based on the text. We'll use a Naive Bayes model for this."
      ],
      "metadata": {
        "id": "Aie8xxrlKSJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the list of filtered words we created to filter the text vector\n",
        "filtered_text = desc_tfidf[:, list(filtered_words)]\n",
        "\n",
        "# Split the X and y sets using train_test_split, setting stratify=y \n",
        "train_X, test_X, train_y, test_y = train_test_split(filtered_text.toarray(), y, stratify=y)\n",
        "\n",
        "# Fit nb to the training sets\n",
        "nb.fit(train_X, train_y)\n",
        "\n",
        "# Print the score of nb on the test sets\n",
        "nb.score(test_X, test_y)"
      ],
      "metadata": {
        "id": "RNxtFOdqKTlx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}