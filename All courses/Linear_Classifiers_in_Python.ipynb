{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Classifiers in Python",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xfrcKfS-SOT"
      },
      "outputs": [],
      "source": [
        "# cheat sheet\n",
        "http://datacamp-community-prod.s3.amazonaws.com/eb807da5-dce5-4b97-a54d-74e89f14266b\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create and fit the model\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test features, print the results\n",
        "pred = knn.predict(X_test)[0]\n",
        "print(\"Prediction for test example 0:\", pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "digits = datasets.load_digits()\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
        "\n",
        "# Apply logistic regression and print scores\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "print('train score:', lr.score(X_train, y_train))\n",
        "print('test score:', lr.score(X_test, y_test))\n",
        "\n",
        "# Apply SVM and print scores\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "print('train score:', svm.score(X_train, y_train))\n",
        "print('test score:', svm.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJVfSD38_iB3",
        "outputId": "659f2604-16e7-439e-fc46-e453295b4e41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score: 1.0\n",
            "test score: 0.9533333333333334\n",
            "train score: 0.9955456570155902\n",
            "test score: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate logistic regression and train\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X, y)\n",
        "\n",
        "# Predict sentiment for a glowing review\n",
        "review1 = \"LOVED IT! This movie was amazing. Top 10 this year.\"\n",
        "review1_features = get_features(review1)\n",
        "print(\"Review:\", review1)\n",
        "print(\"Probability of positive review:\", lr.predict_proba(review1_features)[0,1])\n",
        "\n",
        "# Predict sentiment for a poor review\n",
        "review2 = \"Total junk! I'll never watch a film by that director again, no matter how good the reviews.\"\n",
        "review2_features = get_features(review2)\n",
        "print(\"Review:\", review2)\n",
        "print(\"Probability of positive review:\", lr.predict_proba(review2_features)[0,1])"
      ],
      "metadata": {
        "id": "IfgkfCtjBuQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define the classifiers\n",
        "classifiers = [LogisticRegression(), LinearSVC(),\n",
        "               SVC(), KNeighborsClassifier()]\n",
        "\n",
        "# Fit the classifiers\n",
        "for c in classifiers:\n",
        "    c.fit(X, y)\n",
        "\n",
        "# Plot the classifiers\n",
        "plot_4_classifiers(X, y, classifiers)\n",
        "plt.show()\n",
        "\n",
        "# Nice! As you can see, logistic regression and linear SVM are linear classifiers whereas KNN is not. \n",
        "# The default SVM is also non-linear, but this is hard to see in the plot because it performs poorly with default hyperparameters. \n",
        "# With better hyperparameters, it performs well. "
      ],
      "metadata": {
        "id": "c_OahlfdCnz4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the coefficients\n",
        "model.coef_ = np.array([[-1,1]])\n",
        "model.intercept_ = np.array([-3])\n",
        "\n",
        "# Plot the data and decision boundary\n",
        "plot_classifier(X,y,model)\n",
        "\n",
        "# Print the number of errors\n",
        "num_err = np.sum(y != model.predict(X))\n",
        "print(\"Number of errors:\", num_err)"
      ],
      "metadata": {
        "id": "R7uUAKXtRRRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The squared error, summed over training examples\n",
        "def my_loss(w):\n",
        "    s = 0\n",
        "    for i in range(y.size):\n",
        "        # Get the true and predicted target values for example 'i'\n",
        "        y_i_true = y[i]\n",
        "        y_i_pred = w@X[i]\n",
        "        s = s + (y_i_true - y_i_pred)**2\n",
        "    return s\n",
        "\n",
        "# Returns the w that makes my_loss(w) smallest\n",
        "w_fit = minimize(my_loss, X[0]).x\n",
        "print(w_fit)\n",
        "\n",
        "# Compare with scikit-learn's LinearRegression coefficients\n",
        "lr = LinearRegression(fit_intercept=False).fit(X,y)\n",
        "print(lr.coef_)"
      ],
      "metadata": {
        "id": "rqXXrihsRS6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Mathematical functions for logistic and hinge losses\n",
        "def log_loss(raw_model_output):\n",
        "   return np.log(1+np.exp(-raw_model_output))\n",
        "def hinge_loss(raw_model_output):\n",
        "   return np.maximum(0,1-raw_model_output)\n",
        "\n",
        "# Create a grid of values and plot\n",
        "grid = np.linspace(-2,2,1000)\n",
        "plt.plot(grid, log_loss(grid), label='logistic')\n",
        "plt.plot(grid, hinge_loss(grid), label='hinge')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "f8vXPfhgYha2",
        "outputId": "a9501608-7a5b-492b-bc38-df337f328b1e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The logistic loss, summed over training examples\n",
        "def my_loss(w):\n",
        "    s = 0\n",
        "    for i in range(y.size):\n",
        "        raw_model_output = w@X[i]\n",
        "        s = s + log_loss(raw_model_output * y[i])\n",
        "    return s\n",
        "\n",
        "# Returns the w that makes my_loss(w) smallest\n",
        "w_fit = minimize(my_loss, X[0]).x\n",
        "print(w_fit)\n",
        "\n",
        "# Compare with scikit-learn's LogisticRegression\n",
        "lr = LogisticRegression(fit_intercept=False, C=1000000).fit(X,y)\n",
        "print(lr.coef_)"
      ],
      "metadata": {
        "id": "lBZ7rX9lYh6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and validaton errors initialized as empty list\n",
        "train_errs = list()\n",
        "valid_errs = list()\n",
        "\n",
        "# Loop over values of C_value\n",
        "for C_value in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
        "    # Create LogisticRegression object and fit\n",
        "    lr = LogisticRegression(C=C_value)\n",
        "    lr.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate error rates and append to lists\n",
        "    train_errs.append( 1.0 - lr.score(X_train, y_train))\n",
        "    valid_errs.append( 1.0 - lr.score(X_valid, y_valid))\n",
        "    \n",
        "# Plot results\n",
        "plt.semilogx(C_values, train_errs, C_values, valid_errs)\n",
        "plt.legend((\"train\", \"validation\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_D5i-QeYZOjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify L1 regularization\n",
        "lr = LogisticRegression(solver='liblinear', penalty='l1')\n",
        "\n",
        "# Instantiate the GridSearchCV object and run the search\n",
        "searcher = GridSearchCV(lr, {'C':[0.001, 0.01, 0.1, 1, 10]})\n",
        "searcher.fit(X_train, y_train)\n",
        "\n",
        "# Report the best parameters\n",
        "print(\"Best CV params\", searcher.best_params_)\n",
        "\n",
        "# Find the number of nonzero coefficients (selected features)\n",
        "best_lr = searcher.best_estimator_\n",
        "coefs = best_lr.coef_\n",
        "print(\"Total number of features:\", coefs.size)\n",
        "print(\"Number of selected features:\", np.count_nonzero(coefs))"
      ],
      "metadata": {
        "id": "c-0JnuitcHom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the indices of the sorted cofficients\n",
        "inds_ascending = np.argsort(lr.coef_.flatten()) \n",
        "inds_descending = inds_ascending[::-1]\n",
        "\n",
        "# Print the most positive words\n",
        "print(\"Most positive words: \", end=\"\")\n",
        "for i in range(5):\n",
        "    print(vocab[inds_descending[i]], end=\", \")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Print most negative words\n",
        "print(\"Most negative words: \", end=\"\")\n",
        "for i in range(5):\n",
        "    print(vocab[inds_ascending[i]], end=\", \")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "vRt8DPuicmdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# smaller values of C lead to less confident predictions. That's because smaller C means more regularization, which in turn means smaller coefficients, \n",
        "# which means raw model outputs closer to zero and, thus, probabilities closer to 0.5 after the raw model output is squashed through the sigmoid function. \n",
        "\n",
        "# Set the regularization strength\n",
        "model = LogisticRegression(C=0.1)\n",
        "\n",
        "# Fit and plot\n",
        "model.fit(X,y)\n",
        "plot_classifier(X,y,model,proba=True)\n",
        "\n",
        "# Predict probabilities on training points\n",
        "prob = model.predict_proba(X)\n",
        "print(\"Maximum predicted probability\", np.max(prob))"
      ],
      "metadata": {
        "id": "fkVN5lUDdPxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X,y)\n",
        "\n",
        "# Get predicted probabilities\n",
        "proba = lr.predict_proba(X)\n",
        "\n",
        "# Sort the example indices by their maximum probability\n",
        "proba_inds = np.argsort(np.max(proba,axis=1))\n",
        "\n",
        "# Show the most confident (least ambiguous) digit\n",
        "show_digit(proba_inds[-1], lr)\n",
        "\n",
        "# Show the least confident (most ambiguous) digit\n",
        "show_digit(proba_inds[0], lr)"
      ],
      "metadata": {
        "id": "ahrUGNE9fPIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit one-vs-rest logistic regression classifier\n",
        "lr_ovr = LogisticRegression(multi_class= 'ovr')\n",
        "lr_ovr.fit(X_train, y_train)\n",
        "\n",
        "print(\"OVR training accuracy:\", lr_ovr.score(X_train, y_train))\n",
        "print(\"OVR test accuracy    :\", lr_ovr.score(X_test, y_test))\n",
        "\n",
        "# Fit softmax classifier\n",
        "lr_mn = LogisticRegression(multi_class= 'multinomial')\n",
        "lr_mn.fit(X_train, y_train)\n",
        "\n",
        "print(\"Softmax training accuracy:\", lr_mn.score(X_train, y_train))\n",
        "print(\"Softmax test accuracy    :\", lr_mn.score(X_test, y_test))\n",
        "\n",
        "# the accuracies of the two methods are fairly similar on this data set"
      ],
      "metadata": {
        "id": "gx23eZ-whA6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print training accuracies\n",
        "print(\"Softmax     training accuracy:\", lr_mn.score(X_train, y_train))\n",
        "print(\"One-vs-rest training accuracy:\", lr_ovr.score(X_train, y_train))\n",
        "\n",
        "# Create the binary classifier (class 1 vs. rest)\n",
        "lr_class_1 = LogisticRegression(C=100, multi_class= 'ovr')\n",
        "lr_class_1.fit(X_train, y_train==1)\n",
        "\n",
        "# Plot the binary classifier (class 1 vs. rest)\n",
        "plot_classifier(X_train, y_train==1, lr_class_1)"
      ],
      "metadata": {
        "id": "KEgtxofShlFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use SVC instead of LinearSVC from now on\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create/plot the binary classifier (class 1 vs. rest)\n",
        "svm_class_1 = SVC(decision_function_shape='ovr')\n",
        "svm_class_1.fit(X_train, y_train==1)\n",
        "plot_classifier(X_train, y_train==1, svm_class_1)"
      ],
      "metadata": {
        "id": "F2NwYB5WhmOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_classifier(X, y, svm, lims=(11,15,0,6))\n",
        "\n",
        "# Make a new data set keeping only the support vectors\n",
        "print(\"Number of original examples\", len(X))\n",
        "print(\"Number of support vectors\", len(svm.support_))\n",
        "X_small = X[svm.support_]\n",
        "y_small = y[svm.support_]\n",
        "\n",
        "# Train a new SVM using only the support vectors\n",
        "svm_small = SVC(kernel=\"linear\")\n",
        "svm_small.fit(X_small, y_small)\n",
        "plot_classifier(X_small, y_small, svm_small, lims=(11,15,0,6))"
      ],
      "metadata": {
        "id": "q62XjLXdn7Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate an RBF SVM\n",
        "svm = SVC()\n",
        "\n",
        "# Instantiate the GridSearchCV object and run the search\n",
        "parameters = {'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
        "searcher = GridSearchCV(svm, parameters)\n",
        "searcher.fit(X,y)\n",
        "\n",
        "# Report the best parameters\n",
        "print(\"Best CV params\", searcher.best_params_)"
      ],
      "metadata": {
        "id": "KyGh6Q6QpEae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate an RBF SVM\n",
        "svm = SVC()\n",
        "\n",
        "# Instantiate the GridSearchCV object and run the search\n",
        "parameters = {'C':[0.1, 1, 10], 'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
        "searcher = GridSearchCV(svm, parameters)\n",
        "searcher.fit(X_train, y_train)\n",
        "\n",
        "# Report the best parameters and the corresponding score\n",
        "print(\"Best CV params\", searcher.best_params_)\n",
        "print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "# Report the test accuracy using these best parameters\n",
        "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "CrWQyWHJpXlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We set random_state=0 for reproducibility \n",
        "linear_classifier = SGDClassifier(random_state=0)\n",
        "\n",
        "# Instantiate the GridSearchCV object and run the search\n",
        "parameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n",
        "             'loss':['hinge', 'log']}\n",
        "searcher = GridSearchCV(linear_classifier, parameters, cv=10)\n",
        "searcher.fit(X_train, y_train)\n",
        "\n",
        "# Report the best parameters and the corresponding score\n",
        "print(\"Best CV params\", searcher.best_params_)\n",
        "print(\"Best CV accuracy\", searcher.best_score_)\n",
        "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))\n",
        "\n",
        "#if grid search says 'hinge' then SVC, 'log' logistic Regression\n"
      ],
      "metadata": {
        "id": "y_QzYx4Dphtb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}